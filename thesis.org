#+TITLE: Thesis Stuff

Azure: https://portal.azure.com/#blade/Microsoft_Azure_Education

* Needs work [1/4]
** TODO Implement different losses [3/5]
*** DONE Bernoulli + KL for binary MNIST
    CLOSED: [2019-05-19 Sun 14:22]
*** DONE MSE + KL
    CLOSED: [2019-05-19 Sun 14:21]
*** DONE PSNR + KL
    CLOSED: [2019-05-19 Sun 14:21]
*** TODO VGG
*** TODO GAN + VGG?


** DONE Implement (basic) rejection sampling
   CLOSED: [2019-05-19 Sun 14:20]

** TODO Implement block-based RS?

** TODO Upscale stuff


* Questions [4/10]
** DONE What is the equivalent of the block constraint here?
   CLOSED: [2019-05-31 Fri 10:52]
   - Is there a connection to conditional sampling?
** DONE How much data should we be training on? Good datasets?   
   CLOSED: [2019-05-31 Fri 11:52]
   CC images from FLICKR -> downsample them save as png
   narrow by camera type lens type.

** DONE Is there a reason to further experiment with loss functions?
   CLOSED: [2019-05-31 Fri 12:03]
   How about VGG loss / L1 / L2 only?
   Just use L2 for comparison
   Use GAN for nice pictures

** TODO Is there a good justification for Laplace latent distributions?
** DONE Good image reconstruction activations? Is GDN good?
   CLOSED: [2019-05-31 Fri 11:45]

** TODO Is there a way to get rid of the edge artifacts?
** TODO Use VALID or mirrored SAME padding?
** TODO Using stacked CNN layers instead of one big one?
** TODO Residual CNN architecture?

** TODO Is a Laplace prior justified or should we attempt to use the non-informative one?

     
* How to choose the beta
** report the pareto frontier
** Gaussianise the latent space
** Decorrelate latent representation
** autoregressive structure on Gaussianized network
** Try YUV

   
* Things to do next
** 

* Ideas
** Denoising VAEs -> compress similar images to the same latent representation?


* Issues
** Check edges of images -> use valid padding instead of same maybe?

* Papers [2/9]
** TODO Deep Feature Consistent Variational Autoencoder (Hou et al.)
   [[file:papers/deep_feature_consistent_vae.pdf][Paper]] 
** TODO Denoising Criterion for VAEs (Im et al.)
   [[file:papers/denoising_vaes.pdf][Paper]]
** TODO End-to-end Optimised Image Compression (Balle et al.)
   [[file:papers/ete_image_compression.pdf][Paper]]
** DONE How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks (Sonderby et al.)
   CLOSED: [2019-05-19 Sun 14:36]
   [[file:papers/how_to_train_vaes.pdf][Paper]]
** DONE Loss Functions for Image Restoration with Neural Networks (Zhao et al.)
   CLOSED: [2019-05-19 Sun 14:36]
   [[file:papers/nn_img_loss_fns.pdf][Paper]]
** TODO Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network
   [[file:papers/srgans_mssim.pdf][Paper]]
** TODO VAE-GANs for Probabilistic Compressive Image Recovery: Uncertainty Analysis (Edupuganti et al.)
   [[file:papers/vae_gans.pdf][Paper]]
** TODO Variational Autoencoder for Low Bit-rate Image Compression (CLIC 2018 winner)
   [[file:papers/clic2018_winner.pdf][CLIC 2018 Winner]]

** TODO Variational Image Compression with Scale Hyperprior (Balle et al.)
   [[file:papers/var_comp_with_hyperprior.pdf][Paper]]


* Meeting on 20 May [3/4]
** DONE What is the appropriate way to train the network?
   CLOSED: [2019-05-20 Mon 15:56]
   - In [[file:papers/clic2018_winner.pdf][clic winner]] and [[file:papers/var_comp_with_hyperprior.pdf][Balle 2018]] they suggest downloading stuff from Flickr and using 256x256 cutouts
   *Answer*: just try what's in the paper
** DONE How to make the network work for arbitrary image sizes?
   CLOSED: [2019-05-20 Mon 15:56]
   Would a purely CNN + ResNet based architecture work?
   *Answer*: yes, a pure cnn + resnet is probably the answer
** DONE Is -PSNR + KL the appropriate loss to use?
   CLOSED: [2019-05-20 Mon 15:56]
   - Criticised in [[file:papers/nn_img_loss_fns.pdf][here]]
   *Answer*: just use MSE (Gaussian likelihood)

* Meeting on 27 May

  https://en.wikipedia.org/wiki/Elias_delta_coding
  http://brahma.tcs.tifr.res.in/~prahladh/papers/HJMR/HJMR2010.pdf
* Meeting on 3 June

* Meeting on 10 June

* Meeting on 17 June / Industry day


