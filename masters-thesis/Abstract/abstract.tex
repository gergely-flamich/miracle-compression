% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
\begin{abstract}
  \par
  There has been renewed interest in machine learning (ML) based image
  compression techniques, with recently proposed techniques beating traditional
  lossy image codecs such as JPEG, WebP and BPG in perceptual quality on every
  compression rate. A key advantages of ML algorithms in this field are that
  \textbf{a)} they can adapt to the statistics of each individual image to increase
  compression efficiency much better than any hand-crafted method and
  \textbf{b)} they can be quickly adapted to develop codecs for new media such
  as lightfield cameras, $360^\circ$ images, Virtual Reality (VR), where current
  methdos would struggle and where the develpment of new hand-crafted methods
  could take years.
  \par
  In this thesis we present an introduction to the field of neural image
  compression, first through lens of image compression, then through the lens of
  information theoretic neural compression. We will see how quantization is a
  fundamental block in the lossy image compression pipeline, and emphasize the
  difficulties it presents for gradient-based optimization techniques. We
  review recent influential developments in neural image compression and
  constrast them with each other and see how each method deals with the issues
  of quantization. 
  \par
  Our approach is different: we propose a compression framework that allows us
  to forgo quantization completely. We use this to develop a novel image
  compression algorithm and evaluate its efficiency compare to both classical
  and ML-based approaches on two of the currently most popular perceptual
  quality metrics.
  Surprisingly, with no fine-tuning, we achieve close
  to state-of-the-art performance on low bitrates while slightly underperforming
  on higher bitrates. Finally, we present analysis of important characteristics
  of our method, such as coding time and the effectiveness of our
  chosen model, and discuss key areas where our method could be improved.
\end{abstract}
